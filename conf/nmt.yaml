---
transforms:
  pipe:
  - word_tokenize
  - filter_too_long
  - vocab_numerical
  - to_tensor
  params:
    filter_too_long:
      src_max_len: 10
      tgt_max_len: 10
    vocab_numerical:
      src_vocab: src_vocab.txt
      tgt_vocab: tgt_vocab.txt
model:
  type: rnn
  params:
    rnn:
      n_hiddens: 64
      n_embed: 32
      n_layers: 1
      dropout: 0
    bahdanau:
      n_hiddens: 512
      enc_embed: 256
      dec_embed: 256
      use_birnn: false
      n_layers: 1
      dropout: 0
    luong:
      n_hiddens: 512
      enc_embed: 256
      dec_embed: 256
      use_birnn: false
      score_fn: dot
      n_layers: 1
      dropout: 0
    transformer:
      n_heads: 8
      n_layers: 6
      n_hiddens: 512
      ff_hiddens: 2048
      n_position: 100
      dropout: 0
